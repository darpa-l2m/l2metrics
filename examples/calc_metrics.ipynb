{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) 2019 The Johns Hopkins University Applied Physics Laboratory LLC (JHU/APL).\n",
    "# All Rights Reserved. This material may be only be used, modified, or reproduced\n",
    "# by or for the U.S. Government pursuant to the license rights granted under the\n",
    "# clauses at DFARS 252.227-7013/7014 or FAR 52.227-14. For any other permission,\n",
    "# please contact the Office of Technology Transfer at JHU/APL.\n",
    "\n",
    "# NO WARRANTY, NO LIABILITY. THIS MATERIAL IS PROVIDED “AS IS.” JHU/APL MAKES NO\n",
    "# REPRESENTATION OR WARRANTY WITH RESPECT TO THE PERFORMANCE OF THE MATERIALS,\n",
    "# INCLUDING THEIR SAFETY, EFFECTIVENESS, OR COMMERCIAL VIABILITY, AND DISCLAIMS\n",
    "# ALL WARRANTIES IN THE MATERIAL, WHETHER EXPRESS OR IMPLIED, INCLUDING (BUT NOT\n",
    "# LIMITED TO) ANY AND ALL IMPLIED WARRANTIES OF PERFORMANCE, MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT OF INTELLECTUAL PROPERTY\n",
    "# OR OTHER THIRD PARTY RIGHTS. ANY USER OF THE MATERIAL ASSUMES THE ENTIRE RISK\n",
    "# AND LIABILITY FOR USING THE MATERIAL. IN NO EVENT SHALL JHU/APL BE LIABLE TO ANY\n",
    "# USER OF THE MATERIAL FOR ANY ACTUAL, INDIRECT, CONSEQUENTIAL, SPECIAL OR OTHER\n",
    "# DAMAGES ARISING FROM THE USE OF, OR INABILITY TO USE, THE MATERIAL, INCLUDING,\n",
    "# BUT NOT LIMITED TO, ANY DAMAGES FOR LOST PROFITS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import json\n",
    "import pandas as pd\n",
    "from l2metrics.report import MetricsReport\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure metrics report\n",
    "kwargs = {}\n",
    "\n",
    "perf_measure = {\n",
    "    'argonne': 'score',\n",
    "    'hrl': 'norm_reward',\n",
    "    'sri': 'reward',\n",
    "    'teledyne': 'id_accuracy_cumulative',\n",
    "    'upenn': 'performance',\n",
    "    'example': 'performance'\n",
    "}\n",
    "\n",
    "sg_name = 'example'\n",
    "\n",
    "kwargs['log_dir'] = 'multi_task'\n",
    "# kwargs['log_dir'] = '2-intermediate_alternating-1617337473-4213'\n",
    "# kwargs['log_dir'] = '2-intermediate_permuted-1617337203-309063'\n",
    "# kwargs['log_dir'] = 'sg_anl_ac1_baseline-1613108215-497988'\n",
    "# kwargs['log_dir'] = 'sg_hrl_stellar_m9_0-1613171440-1474369'\n",
    "# kwargs['log_dir'] = 'sg_hrl_base0_0-1614139713-1434264'\n",
    "# kwargs['log_dir'] = 'sg_sri_scenario_c_d_x5_1M-1613056361-6548986'\n",
    "# kwargs['log_dir'] = 'sg_teledyne_m9_updated-1613773889-282773'\n",
    "# kwargs['log_dir'] = 'sg_upenn_1-low_1-easy-20210211T034548.051120'\n",
    "\n",
    "kwargs['ste_averaging_method']='time'\n",
    "kwargs['perf_measure'] = perf_measure[sg_name]\n",
    "kwargs['aggregation_method'] = 'median'\n",
    "kwargs['maintenance_method'] = 'both'\n",
    "kwargs['transfer_method'] = 'both'\n",
    "kwargs['normalization_method'] = 'task'\n",
    "kwargs['smoothing_method'] = 'flat'\n",
    "# kwargs['data_range_file'] = 'data_range.json'\n",
    "kwargs['show_raw_data'] = True\n",
    "kwargs['remove_outliers'] = False\n",
    "kwargs['do_plot'] = True\n",
    "kwargs['do_save'] = False\n",
    "kwargs['do_save_config'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data range data for normalization and standardize names to lowercase\n",
    "if 'data_range_file' in kwargs.keys():\n",
    "    with open(kwargs['data_range_file']) as config_json:\n",
    "        data_range = json.load(config_json)\n",
    "        data_range = {key.lower(): val for key, val in data_range.items()}\n",
    "else:\n",
    "    data_range = None\n",
    "\n",
    "kwargs['data_range'] = data_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics report\n",
    "report = MetricsReport(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to log data\n",
    "# report.add_noise(mean=0.0, std=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics in order of their addition to the metrics list.\n",
    "report.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print log summary by LX and EX counts\n",
    "log_summary_df = report.log_summary()\n",
    "display(log_summary_df)\n",
    "\n",
    "print(f'\\nTotal number of experiences: {report._log_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lifetime metrics:')\n",
    "display(report.lifetime_metrics_df)\n",
    "\n",
    "print('\\nTask metrics:')\n",
    "display(report.task_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance curves for scenario\n",
    "if kwargs['do_plot']:\n",
    "    report.plot(save=kwargs['do_save'], show_raw_data=kwargs['show_raw_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tasks and their corresponding STE\n",
    "if kwargs['do_plot']:\n",
    "    report.plot_ste_data(save=kwargs['do_save'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print block summary\n",
    "print(tabulate(report.block_info, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print metrics per regime\n",
    "print(tabulate(report.regime_metrics_df.fillna('N/A'),\n",
    "               headers='keys', tablefmt='psql', floatfmt=\".2f\"))"
   ]
  }
 ]
}