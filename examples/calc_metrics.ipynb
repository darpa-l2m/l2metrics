{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('venv36')"
  },
  "interpreter": {
   "hash": "2597f07d1e20e98cf7cfcf385b8c0110fb64187439c69d940b99f69f38ff003b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# (c) 2019 The Johns Hopkins University Applied Physics Laboratory LLC (JHU/APL).\r\n",
    "# All Rights Reserved. This material may be only be used, modified, or reproduced\r\n",
    "# by or for the U.S. Government pursuant to the license rights granted under the\r\n",
    "# clauses at DFARS 252.227-7013/7014 or FAR 52.227-14. For any other permission,\r\n",
    "# please contact the Office of Technology Transfer at JHU/APL.\r\n",
    "\r\n",
    "# NO WARRANTY, NO LIABILITY. THIS MATERIAL IS PROVIDED “AS IS.” JHU/APL MAKES NO\r\n",
    "# REPRESENTATION OR WARRANTY WITH RESPECT TO THE PERFORMANCE OF THE MATERIALS,\r\n",
    "# INCLUDING THEIR SAFETY, EFFECTIVENESS, OR COMMERCIAL VIABILITY, AND DISCLAIMS\r\n",
    "# ALL WARRANTIES IN THE MATERIAL, WHETHER EXPRESS OR IMPLIED, INCLUDING (BUT NOT\r\n",
    "# LIMITED TO) ANY AND ALL IMPLIED WARRANTIES OF PERFORMANCE, MERCHANTABILITY,\r\n",
    "# FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT OF INTELLECTUAL PROPERTY\r\n",
    "# OR OTHER THIRD PARTY RIGHTS. ANY USER OF THE MATERIAL ASSUMES THE ENTIRE RISK\r\n",
    "# AND LIABILITY FOR USING THE MATERIAL. IN NO EVENT SHALL JHU/APL BE LIABLE TO ANY\r\n",
    "# USER OF THE MATERIAL FOR ANY ACTUAL, INDIRECT, CONSEQUENTIAL, SPECIAL OR OTHER\r\n",
    "# DAMAGES ARISING FROM THE USE OF, OR INABILITY TO USE, THE MATERIAL, INCLUDING,\r\n",
    "# BUT NOT LIMITED TO, ANY DAMAGES FOR LOST PROFITS."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import necessary modules\r\n",
    "import json\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "from l2metrics.report import MetricsReport\r\n",
    "from tabulate import tabulate\r\n",
    "\r\n",
    "pd.options.display.float_format = '{:,.2f}'.format\r\n",
    "%matplotlib ipympl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Configure metrics report\r\n",
    "kwargs = {}\r\n",
    "kwargs['log_dir'] = 'multi_task'\r\n",
    "kwargs['variant_mode'] = 'aware'\r\n",
    "kwargs['ste_averaging_method']='metrics'\r\n",
    "kwargs['perf_measure'] = 'performance'\r\n",
    "kwargs['aggregation_method'] = 'mean'\r\n",
    "kwargs['maintenance_method'] = 'both'\r\n",
    "kwargs['transfer_method'] = 'both'\r\n",
    "kwargs['normalization_method'] = 'task'\r\n",
    "kwargs['smoothing_method'] = 'flat'\r\n",
    "kwargs['window_length'] = None\r\n",
    "kwargs['clamp_outliers'] = True\r\n",
    "kwargs['data_range_file'] = None # 'data_range.json'\r\n",
    "kwargs['show_eval_lines'] = True\r\n",
    "kwargs['do_plot'] = True\r\n",
    "kwargs['do_save'] = False\r\n",
    "kwargs['do_save_settings'] = False\r\n",
    "\r\n",
    "output_dir = Path('results')\r\n",
    "output = 'll_metrics'\r\n",
    "\r\n",
    "# Create output directory if it doesn't exist\r\n",
    "if kwargs['do_save'] or kwargs['do_save_settings']:\r\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load data range data for normalization and standardize names to lowercase\r\n",
    "if kwargs['data_range_file']:\r\n",
    "    with open(kwargs['data_range_file']) as config_json:\r\n",
    "        data_range = json.load(config_json)\r\n",
    "        data_range = {key.lower(): val for key, val in data_range.items()}\r\n",
    "else:\r\n",
    "    data_range = None\r\n",
    "\r\n",
    "kwargs['data_range'] = data_range"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize metrics report\r\n",
    "report = MetricsReport(**kwargs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add noise to log data\r\n",
    "# report.add_noise(mean=0.0, std=1.0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate metrics in order of their addition to the metrics list.\r\n",
    "report.calculate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print log summary by LX and EX counts\r\n",
    "log_summary_df = report.log_summary()\r\n",
    "display(log_summary_df)\r\n",
    "\r\n",
    "print(f'\\nTotal number of experiences: {report._log_data.shape[0]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Lifetime metrics:')\r\n",
    "display(report.lifetime_metrics_df)\r\n",
    "\r\n",
    "print('\\nTask metrics:')\r\n",
    "display(report.task_metrics_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot performance curves for scenario\r\n",
    "if kwargs['do_plot']:\r\n",
    "    report.plot(save=kwargs['do_save'], show_eval_lines=kwargs['show_eval_lines'], \\\r\n",
    "        output_dir=str(output_dir))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot tasks and their corresponding STE\r\n",
    "if kwargs['do_plot']:\r\n",
    "    report.plot_ste_data(save=kwargs['do_save'], output_dir=str(output_dir))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save data to feather file\r\n",
    "if kwargs['do_save']:\r\n",
    "    report.save_data(output_dir=str(output_dir), filename=output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print block summary\r\n",
    "print(tabulate(report.block_info, headers='keys', tablefmt='psql'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print metrics per regime\r\n",
    "print(tabulate(report.regime_metrics_df.fillna('N/A'),\r\n",
    "               headers='keys', tablefmt='psql', floatfmt=\".2f\"))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}